{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pytest-impacted","text":"<p>A pytest plugin that selectively runs tests impacted by codechanges via git introspection, ASL parsing, and dependency graph analysis.</p> <ul> <li>Configurable to meet your demands for both local and CI-driven invocations. </li> <li>Built using a modern, best-of-breed Python stack, using astroid for   Python code AST, NetworkX for dependency graph analysis, and GitPython for interacting with git repositories. </li> <li>Strategy-based architecture allowing for different change impact analysis approaches, including specialized pytest-specific handling (e.g., <code>conftest.py</code> dependencies). </li> <li>Modular codebase with high unit-test coverage to ensure solid, reliable performance in CI and production environments. </li> </ul> <p>[!CAUTION] This project is still currently in alpha development phase. Do not use it in mission critical applications without close supervision of its output and performance. Please report bugs via the Issues tab.</p>"},{"location":"#overview","title":"Overview","text":"<p>Sometimes code repositories can become encumbered with a large codebase and a large unit-test codebase to match. In those cases often CI builds become slow and painful due to the need to run all the unit-tests on every CI build. Existing solutions include parallelizing or splitting the tests (e.g. via pytest-split or pytest-xdist), however these often run into trouble too when tests rely on resources such as databases that cannot be easily \"shared\" between concurrent runs. Moreover, when using solutions such as pytest-split or pytest-xdist, even with multiple database instances, it is often the case that each thread / split of tests takes a long time to run, on top of the overhead introduced by spawning N many databases.</p> <p>An alternative solution is to try and selectively mark tests that have been affected by recent changes, e.g. as relative to a base branch when we are on a feature branch. This plugin takes this approach. It uses a combination of static analysis (parsing the AST for python modules in a package and building a dependency graph of imports) and git introspection to flag tests that should be re-run.</p> <p>The philosophy is to err on the side of caution; we currently do not attempt to isolate changes on a line-by-line basis, but rather favor 'false positives' by simply following the chain of dependencies from any file that was modified in any way according to the git history, all the way to any unit-test file that imports it directly or transitively.</p>"},{"location":"#impact-analysis-strategies","title":"Impact Analysis Strategies","text":"<p>The plugin uses a strategy-based architecture that allows for different approaches to determine which tests are impacted by code changes. This modular design enables specialized handling for different scenarios:</p>"},{"location":"#ast-impact-strategy","title":"AST Impact Strategy","text":"<p>The default strategy uses static analysis by parsing Python ASTs to build a dependency graph and follow import chains from changed modules to affected tests.</p>"},{"location":"#pytest-impact-strategy","title":"Pytest Impact Strategy","text":"<p>A pytest-specific strategy that extends AST analysis with additional pytest-specific dependency detection:</p> <ul> <li><code>conftest.py</code> handling: When <code>conftest.py</code> files are modified, all tests in the same directory and subdirectories are considered impacted, as these files provide fixtures and configuration that affect test execution.</li> <li>Future pytest-specific dependencies can be easily added to this strategy.</li> </ul>"},{"location":"#composite-strategy","title":"Composite Strategy","text":"<p>Multiple strategies can be combined to provide comprehensive impact analysis, ensuring no affected tests are missed while maintaining performance.</p>"},{"location":"#why-another-such-plugin","title":"Why another such plugin?","text":"<p>We originally looked for such a plugin to already exist. For completeness we mention these here and our impression:</p> <ul> <li>pytest-testmon is probably the most popular alternative. This may be a fine choice - they are still actively maintained at the time of writing, and go beyond what <code>pytest-impacted</code> does by isolating more granular changes to mark affected tests, based on logic used by the coverage package. In our attempts to use it we ran into various errors we could not easily figure out when using it in conjunction with other plugins such as <code>coverage</code> and <code>pytest-split</code>, but YMMV - definitely give it a try if you want to look at other options.</li> <li>pytest-affected - no homepage / repo, seems unmaintained.</li> <li>pytest-picked - seems more recently maintained, however only seems to run tests from files that were directly modified rather than perform any static analysis to transitively identify tests based on updated source.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>You can install \"pytest-impacted\" via <code>pip</code>from <code>PyPI</code>:</p> <pre><code>$ pip install pytest-impacted\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#local-unstaged-changes","title":"Local unstaged changes","text":"<p>Use as a pytest plugin. Examples for invocation:</p> <pre><code>$ pytest --impacted --impacted-git-mode=unstaged --impacted-module=&lt;my_root_module_name&gt;\n</code></pre> <p>This will run all unit-tests impacted by changes to files which have unstaged modifications in the current active git repository.</p>"},{"location":"#changes-committed-to-current-git-branch","title":"Changes committed to current git branch","text":"<pre><code>$ pytest --impacted --impacted-git-mode=branch --impacted-base-branch=main --impacted-module=&lt;my_root_module_name&gt;\n</code></pre> <p>this will run all unit-tests impacted by changes to files which have been modified via any existing commits to the current active branch, as compared to the base branch passed in the <code>--impacted-base-branch</code> parameter.</p> <p>As an added bonus, note that you can pass git expressions to the base branch parameter as would be permissible when using git diff - e.g.:</p> <p>$ pytest --impacted --impacted-git-mode=branch --impacted-base-branch=\"HEAD~4\" --impacted-module= <p>This can be useful in some scenarios as well.</p>"},{"location":"#external-tests-directory","title":"External tests directory","text":"<p>As another common use case, In some projects the tests directory exists outside of the namespace package. In those cases you can use the <code>--impacted-tests-dir</code> option to make sure those test files are included in the dependency tree and correctly considered for impact analysis:</p> <pre><code>$ pytest --impacted --impacted-git-mode=unstaged --impacted-module=&lt;my_root_module_name&gt; --impacted-tests-dir=tests/\n</code></pre>"},{"location":"#ci-integration","title":"CI Integration","text":"<p>When using this plugin in CI, it is sometimes desirable to generate the list of impacted test files in one stage where we have access to the git CLI (and perhaps required credentials), and then invoke running these in a separate step later in the CI pipeline. This can be achieved with the <code>impacted-tests</code> CLI included with the plugin, which supports the same arguments as the plugin itself:</p> <pre><code>$ impacted-tests --module=&lt;my_root_module_name&gt; --git-mode=branch --base-branch=main &gt; impacted_tests.txt\n</code></pre> <p>In some later step of your CI can then run:</p> <pre><code>$ pytest @impacted_tests.txt\n</code></pre>"},{"location":"#testing","title":"Testing","text":"<p>Invoke unit-tests with:</p> <pre><code>uv run python -m pytest\n</code></pre> <p>Linting, formatting, static type checks etc. are all managed via pre-commit hooks. These will run automatically on every commit. You can invoke these manually on all files with:</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"usage/","title":"Usage Guide: pytest-impacted","text":"<p><code>pytest-impacted</code> is a pytest plugin that selectively runs only the tests impacted by code changes, using git introspection, AST parsing, and dependency graph analysis with a strategy-based architecture.</p>"},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<p>Activate the plugin by passing the --impacted flag to pytest. This will run only the tests affected by your recent code changes.</p> <p>Example: Run tests impacted by unstaged changes</p> <pre><code>pytest --impacted --impacted-git-mode=unstaged\n</code></pre> <p>This command will run all unit tests impacted by files with unstaged modifications in your current git repository.</p> <p>Example: Run tests impacted by all cumulative changes to current branch relative to given base branch</p> <pre><code>pytest --impacted --impacted-git-mode=branch --impacted-base-branch=main\n</code></pre> <p>This command will run all unit tests impacted by files changed in commits on your current branch, compared to the main branch.</p>"},{"location":"usage/#impact-analysis-strategies","title":"Impact Analysis Strategies","text":"<p>The plugin uses a modular strategy-based architecture to determine which tests are affected by code changes:</p>"},{"location":"usage/#ast-impact-strategy-default","title":"AST Impact Strategy (Default)","text":"<p>Uses static analysis to parse Python ASTs, build dependency graphs, and follow import chains from changed modules to affected tests.</p>"},{"location":"usage/#pytest-impact-strategy","title":"Pytest Impact Strategy","text":"<p>Extends AST analysis with pytest-specific dependency detection:</p> <ul> <li><code>conftest.py</code> handling: When <code>conftest.py</code> files are modified, all tests in the same directory and subdirectories are considered impacted</li> <li>Future pytest-specific dependencies can be easily added</li> </ul>"},{"location":"usage/#composite-strategy","title":"Composite Strategy","text":"<p>Multiple strategies can be combined for comprehensive analysis while maintaining performance.</p>"},{"location":"usage/#typical-workflows","title":"Typical Workflows","text":"<ul> <li> <p>Local Development: Quickly run only the tests affected by your current changes before committing.</p> </li> <li> <p>Continuous Integration: Speed up CI pipelines by running only the tests impacted by changes in a pull request.</p> </li> </ul>"}]}